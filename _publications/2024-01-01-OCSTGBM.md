---
title: "OCS-TGBM: Intelligent Analysis of Organic Chemical Synthesis Based on Topological Data Analysis and LightGBM"
collection: publications
category: journal
permalink: /publications/2024-01-01-OCSTGBM
excerpt: |
    <div style="display: flex; align-items: center; width: 97%;">
        <img src='/files/papers/OCS-TGBM/OCS-TGBM.jpg' style="max-width: 250px; margin-right: 10px;">
        <p style="font-size: 16px; margin: 5px 0 0 20px; margin-left: 0px; color: #666; text-align: justify;">
            This work proposes OCS-TGBM, an intelligent organic chemical synthesis analysis model, which combines topological data analysis (TDA) and Light Gradient Boosting Machine (LightGBM). OCS-TGBM aims at deeply exploring the internal relationship between reaction conditions and yield, and obtaining high-yield reaction conditions and combinations. Additionally, in order to further enhance the generalization of OCS-TGBM, we design a stratified diversity sampling strategy for LightGBM in the training stage. Experiments show that OCS-TGBM is superior to other methods (e.g., XGBoost, SVR and MLPR) in analyzing and predicting the reaction performance of high-throughput organic chemical synthesis.
        </p>
    </div>
# indexed date
date: 2024-01-01
prefix-venue: 'In'
venue: 'MATCH-COMMUNICATIONS IN MATHEMATICAL AND IN COMPUTER CHEMISTRY'
authors: "Yanhui Guo*, Lichao Peng*, Zixin Li, Meng'en Qin, Xue Jiao, Yun Chai, and Xiaohui Yang‚Ä† (* equal contribution, ‚Ä† corresponding author)."
# slidesurl: ''
paperurl: 'https://match.pmf.kg.ac.rs/electronic_versions/Match91/n3/match91n3_557-592.pdf'
code: 'https://github.com/mason-ching/OCS-TGBM'
# project_page: ''
bibtexurl: 'http://mason-ching.github.io/files/papers/OCS-TGBM/OCS-TGBM.bib'
# APA format
# citation: 'Guo, Y., Peng, L., Li, Z., Qin, M. E., Jiao, X., Chai, Y., & Yang, X. (2024). &quot;OCS-TGBM: Intelligent Analysis of Organic Chemical Synthesis Based on Topological Data Analysis and LightGBM.&quot; <i>MATCH-COMMUNICATIONS IN MATHEMATICAL AND IN COMPUTER CHEMISTRY</i>, 91(3), 557-592.'
---
# Introduction

<p style="text-align: justify; width: 100%;">
    Organic synthesis has been widely used in drug discovery and development. The intelligent yield prediction and analysis of high-throughput coupling reaction is one of the vital and challenging research hotspots in the field of organic synthesis. However, the existing methods focus on intelligent prediction rather than study and interpret the internal relationship between reaction conditions and yield. For tackling this problem, we propose OCS-TGBM, an intelligent organic synthesis analysis model by combining topological data analysis (TDA) and Light Gradient Boosting Machine (LightGBM). OCS-TGBM can deeply explore the internal relationship between reaction conditions and yield, and obtain high-yield reaction conditions and combinations. In order to further enhance the generalization of OCS-TGBM, we also design a stratified diversity sampling strategy for LightGBM in the training stage based on TDA clustering. Experimental results show that the OCS-TGBM model is superior to other methods in analyzing and predicting the reaction performance of high-throughput organic synthesis. And it provides intelligent assistance for the optimal design of the reaction system and the evaluation of reaction conditions, thus greatly accelerating the process of the drug discovery and development.
</p>
<div align="center">
  <img src="/files/papers/OCS-TGBM/reactant.jpg" alt="Reactant" width="90%" />
  <p><em>Figure 1. Some reactants of Buchwald-Hartwig amination reaction.</em></p>
</div>

# Method

## 1. Topological Data Analysis and Multi-Factor Analysis of Variance

- Cluster various reaction conditions and the corresponding yield mean based on topological data analysis, identifying more high-yield conditions.

<div align="center">
  <img src="/files/papers/OCS-TGBM/OCS-TGBM.jpg" alt="Cluster" width="90%" />
  <p><em>Figure 2. Cluster visualization.</em></p>
</div>

- Analyze the combination effects of additives, aryls, bases and ligands on yield based on multi-factor analysis of variance, identifying the optimal combination of reaction conditions.

<div align="center">
  <img src="/files/papers/OCS-TGBM/multi-factor anova.jpg" alt="ANOVA" width="90%" />
  <p><em>Figure 3. Pairwise interaction plot of additive, aryl, base, ligand.</em></p>
</div>

## 2. LightGBM for Yield Prediction

- Learning rate setting by cross-validation and grid search.

<div align="center">
  <img src="/files/papers/OCS-TGBM/grid search.jpg" alt="Learning Rate" width="60%" />
  <p><em>Figure 4. Grid search for learning rate.</em></p>
</div>

- Superior yield prediction accuracy and speed compared to other methods.

<div align="center">
  <img src="/files/papers/OCS-TGBM/prediction plot.jpg" alt="ANOVA" width="90%" />
  <p><em>Figure 5. Prediction performances of different models.</em></p>
</div>

## 3. Stratified Diversity Sampling

<p style="text-align: justify; width: 100%;">
    Stratified diversity sampling combines the advantages of stratified sampling (ensure coverage of all categories) and diversity sampling (increase variation in the training set). It is used to sample the training samples in the training stage, improving the representativeness and out-of-fold generalization of OCS-TGBM. The sampling steps are as follows:
</p>

- (1) Based on TDA clustering, the dataset is divided into several strata (layers or categories). For each layer, randomly select 10% of the data as the initial **labeled** set, and assign the remaining 90% as **unlabeled**.

- (2) For each unlabeled data point, calculate the cosine similarity with all labeled data points:

   $$
   \cos(\theta) = \frac{\sum_{k=1}^{n} x_{1k} x_{2k}}{\sqrt{\sum_{k=1}^{n} x_{1k}^2} \cdot \sqrt{\sum_{k=1}^{n} x_{2k}^2}},
   $$

   where $$x_{1k}$$ represents the labeled sample, and $$x_{2k}$$ the unlabeled sample.

- (3) Sort the similarity values of each unlabeled sample to the labeled set in ascending order (i.e., least similar samples come first).

- (4) Choose the top-ùëö most dissimilar unlabeled samples and add them to the labeled set. Remove these samples from the unlabeled set.

- (5) Repeat steps (2)-(4) until the labeled set reaches **n%** of the total data. The **labeled set** $$(A \times n\%)$$ becomes the **training set**, and the **unlabeled set** $$(A \times (1 - n\%))$$ becomes the **testing set**.